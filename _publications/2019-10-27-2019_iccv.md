---
title: "U-CAM: Visual Explanation using Uncertainty based Class Activation Maps"
collection: publications
permalink: /publication/2019-10-27-2019_iccv
excerpt: 'Understanding and explaining deep learning models is an imperative task. Towards this, we propose a method that obtains gradient-based certainty estimates that also provide visual attention maps. Particularly, we solve for visual question answering task. We incorporate modern probabilistic deep learning methods that we further improve by using the gradients for these estimates. These have two-fold benefits: a) improvement in obtaining the certainty estimates that correlate better with misclassified samples and b) improved attention maps that provide state-of-the-art results in terms of correlation with human attention regions. The improved attention maps result in consistent improvement for various methods for visual question answering. Therefore, the proposed technique can be thought of as a recipe for obtaining improved certainty estimates and explanation for deep learning models. We provide detailed empirical analysis for the visual question answering task on all standard benchmarks and comparison with state of the art methods.'
date: 2019-10-27
venue: 'IEEE International Conference on Computer Vision (ICCV)'
paperurl: 'https://delta-lab-iitk.github.io/U-CAM/'
citation: 'Badri N. Patro, Mayank Lunayach, Shivansh Patel and Vinay P. Namboodiri, “U-CAM: Visual Explanation using Uncertainty based Class Activation Maps”, <i>Proceedings of IEEE International Conference on Computer Vision (ICCV)</i>Seoul, South Korea, October 2019.'
---

<a href='https://delta-lab-iitk.github.io/U-CAM/'>Download paper here</a>

Understanding and explaining deep learning models is an imperative task. Towards this, we propose a method that obtains gradient-based certainty estimates that also provide visual attention maps. Particularly, we solve for visual question answering task. We incorporate modern probabilistic deep learning methods that we further improve by using the gradients for these estimates. These have two-fold benefits: a) improvement in obtaining the certainty estimates that correlate better with misclassified samples and b) improved attention maps that provide state-of-the-art results in terms of correlation with human attention regions. The improved attention maps result in consistent improvement for various methods for visual question answering. Therefore, the proposed technique can be thought of as a recipe for obtaining improved certainty estimates and explanation for deep learning models. We provide detailed empirical analysis for the visual question answering task on all standard benchmarks and comparison with state of the art methods.

Recommended citation: Badri N. Patro, Mayank Lunayach, Shivansh Patel and Vinay P. Namboodiri, “U-CAM: Visual Explanation using Uncertainty based Class Activation Maps”, <i>Proceedings of IEEE International Conference on Computer Vision (ICCV)</i>Seoul, South Korea, October 2019.